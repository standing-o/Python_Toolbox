{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Probability Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision\n",
    "# pip install -U d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.distributions import multinomial\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dice! : {1,â€¦,6} are equally likely to occur -> probability 1/6\n",
    "- estimate of the probability of a given event  \n",
    "\n",
    "-> The law of large numbers tell us that as the number of tosses grows this estimate will draw closer and closer to the true underlying probability.\n",
    "\n",
    "-> loop? (x) multiple samples at once (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_probs = torch.ones([6]) / 6\n",
    "multinomial.Multinomial(1, fair_probs).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 0., 2., 2., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial.Multinomial(10, fair_probs).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after each of the 1000 rolls, how many times each number was rolled.   \n",
    "\n",
    "-> we calculate the relative frequency as the estimate of the true probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1510, 0.1710, 0.1490, 0.1800, 0.1800, 0.1690])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = multinomial.Multinomial(1000, fair_probs).sample()\n",
    "counts / 1000  # Relative frequency as the estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we know that each outcome has true probability 1/6 , roughly 0.167 -> good results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualize how these probabilities converge over time towards the true probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = multinomial.Multinomial(10, fair_probs).sample((500,))\n",
    "cum_counts = counts.cumsum(dim=0)\n",
    "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
    "\n",
    "d2l.set_figsize((6, 4.5))\n",
    "for i in range(6):\n",
    "    d2l.plt.plot(estimates[:, i].numpy(), label=(\"P(die=\" + str(i + 1) + \")\"))\n",
    "d2l.plt.axhline(y=0.167, color='black', linestyle='dashed')\n",
    "d2l.plt.gca().set_xlabel('Groups of experiments')\n",
    "d2l.plt.gca().set_ylabel('Estimated probability')\n",
    "d2l.plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
